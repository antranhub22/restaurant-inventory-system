import { ImageAnnotatorClient } from '@google-cloud/vision';
import dotenv from 'dotenv';

dotenv.config();

class MockVisionClient {
  async documentTextDetection({ image, imageContext }: any) {
    console.log('üîç Mock OCR Service');
    console.log('Image size:', image.content.length, 'bytes');
    console.log('Language hints:', imageContext?.languageHints || []);

    // Return mock data that matches actual Vision API structure
    return [{
      fullTextAnnotation: {
        text: 'MOCK OCR RESULT\nC·ª¨A H√ÄNG TH·ª∞C PH·∫®M ABC\nH√ìA ƒê∆†N B√ÅN H√ÄNG\n\nG·∫°o t√°m xoan: 50,000ƒë\nD·∫ßu ƒÉn: 25,000ƒë\nN∆∞·ªõc m·∫Øm: 15,000ƒë\n\nT·ªïng c·ªông: 90,000ƒë\nTi·ªÅn kh√°ch ƒë∆∞a: 100,000ƒë\nTi·ªÅn th·ª´a: 10,000ƒë\n\nC·∫£m ∆°n qu√Ω kh√°ch!',
        pages: [{
          blocks: [{
            boundingBox: {
              vertices: [
                { x: 10, y: 10 },
                { x: 400, y: 10 },
                { x: 400, y: 300 },
                { x: 10, y: 300 }
              ]
            },
            paragraphs: [{
              words: [{
                symbols: [
                  { text: 'C' }, { text: '·ª¨' }, { text: 'A' }, { text: ' ' },
                  { text: 'H' }, { text: '√Ä' }, { text: 'N' }, { text: 'G' }
                ]
              }]
            }],
            confidence: 0.92
          }]
        }]
      }
    }];
  }

  async textDetection({ image, imageContext }: any) {
    console.log('üîç Mock Text Detection Service');
    return [{
      textAnnotations: [{
        description: 'MOCK OCR RESULT',
        boundingPoly: {
          vertices: [
            { x: 0, y: 0 },
            { x: 100, y: 0 },
            { x: 100, y: 50 },
            { x: 0, y: 50 }
          ]
        }
      }]
    }];
  }
}

// Check if Google Cloud Vision credentials are available
function hasGoogleCloudCredentials(): boolean {
  return !!(
    process.env.GOOGLE_CLOUD_PROJECT_ID && 
    process.env.GOOGLE_CLOUD_CLIENT_EMAIL && 
    process.env.GOOGLE_CLOUD_PRIVATE_KEY
  );
}

// Initialize the client
let visionClient: ImageAnnotatorClient | MockVisionClient;

if (process.env.NODE_ENV === 'production' && hasGoogleCloudCredentials()) {
  // Production with credentials: Use real Google Cloud Vision client
  console.log('‚úÖ Using Google Cloud Vision API with credentials');
  visionClient = new ImageAnnotatorClient({
    credentials: {
      client_email: process.env.GOOGLE_CLOUD_CLIENT_EMAIL,
      private_key: process.env.GOOGLE_CLOUD_PRIVATE_KEY?.replace(/\\n/g, '\n'),
    },
    projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
    // T·ªëi ∆∞u h√≥a c·∫•u h√¨nh cho OCR
    apiEndpoint: 'vision.googleapis.com',
    retry: {
      retries: 3,
      factor: 2,
      minTimeout: 1000,
      maxTimeout: 10000,
    },
    // TƒÉng timeout cho OCR processing
    timeout: 60000, // 60 seconds
  });
} else {
  // Development or Production without credentials: Use mock client
  const reason = process.env.NODE_ENV === 'production' 
    ? 'Missing Google Cloud credentials' 
    : 'Development mode';
  console.log(`‚ö†Ô∏è Using mock Vision client (${reason})`);
  visionClient = new MockVisionClient();
}

export default visionClient; 